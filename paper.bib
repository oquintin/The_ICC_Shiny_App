@article{Turner2005,
   abstract = {<p>Numerous estimates for the intracluster correlation coefficient (ICC) are available in research databases and publications. When planning a cluster randomized trial, an anticipated value for the ICC is required; currently, researchers base their choice informally on the magnitude of previous ICC estimates. In this paper, we make use of the wealth of ICC information by formally constructing informative prior distributions, while acknowledging the varying relevance and precision of the estimates available. Typically, for a planned trial in a given clinical setting, multiple relevant ICC estimates are available from each of several completed studies. Our preferred model allows for the imprecision in each ICC estimate around its underlying true value and, separately, allows for the similarity of ICC values from the same study. The relevance of each previous estimate to the planned clinical setting is considered, and estimates corresponding to less relevant outcomes or population types are given less influence. We find that such downweighting can increase the precision of the anticipated ICC. In trial design, the prior distribution constructed allows uncertainty about the ICC to be acknowledged, and we describe how to choose a design that provides adequate power across the range of likely ICC values. Prior information on the ICC can also be incorporated in analysis of the trial data, when taking a Bayesian approach. The methods proposed enable available ICC information to be summarised appropriately by an informative prior distribution, which is of direct practical use in cluster randomized trials.</p>},
   author = {Rebecca M Turner and Simon G Thompson and David J Spiegelhalter},
   doi = {10.1191/1740774505cn072oa},
   issn = {1740-7745},
   issue = {2},
   journal = {Clinical Trials},
   month = {4},
   pages = {108-118},
   title = {Prior distributions for the intracluster correlation coefficient, based on multiple previous estimates, and their application in cluster randomized trials},
   volume = {2},
   year = {2005}
}
@article{LCarrasco2022,
   author = {Josep L. Carrasco},
   doi = {10.32614/RJ-2022-034},
   issn = {2073-4859},
   issue = {2},
   journal = {The R Journal},
   month = {10},
   pages = {230-244},
   title = {iccCounts: An R Package to Estimate the Intraclass Correlation Coefficient for Assessing Agreement with Count Data},
   volume = {14},
   year = {2022}
}
@article{Korevaar2021,
   abstract = {Background: Sample size calculations for longitudinal cluster randomised trials, such as crossover and stepped-wedge trials, require estimates of the assumed correlation structure. This includes both within-period intra-cluster correlations, which importantly differ from conventional intra-cluster correlations by their dependence on period, and also cluster autocorrelation coefficients to model correlation decay. There are limited resources to inform these estimates. In this article, we provide a repository of correlation estimates from a bank of real-world clustered datasets. These are provided under several assumed correlation structures, namely exchangeable, block-exchangeable and discrete-time decay correlation structures. Methods: Longitudinal studies with clustered outcomes were collected to form the CLustered OUtcome Dataset bank. Forty-four available continuous outcomes from 29 datasets were obtained and analysed using each correlation structure. Patterns of within-period intra-cluster correlation coefficient and cluster autocorrelation coefficients were explored by study characteristics. Results: The median within-period intra-cluster correlation coefficient for the discrete-time decay model was 0.05 (interquartile range: 0.02–0.09) with a median cluster autocorrelation of 0.73 (interquartile range: 0.19–0.91). The within-period intra-cluster correlation coefficients were similar for the exchangeable, block-exchangeable and discrete-time decay correlation structures. Within-period intra-cluster correlation coefficients and cluster autocorrelations were found to vary with the number of participants per cluster-period, the period-length, type of cluster (primary care, secondary care, community or school) and country income status (high-income country or low- and middle-income country). The within-period intra-cluster correlation coefficients tended to decrease with increasing period-length and slightly decrease with increasing cluster-period sizes, while the cluster autocorrelations tended to move closer to 1 with increasing cluster-period size. Using the CLustered OUtcome Dataset bank, an RShiny app has been developed for determining plausible values of correlation coefficients for use in sample size calculations. Discussion: This study provides a repository of intra-cluster correlations and cluster autocorrelations for longitudinal cluster trials. This can help inform sample size calculations for future longitudinal cluster randomised trials.},
   author = {Elizabeth Korevaar and Jessica Kasza and Monica Taljaard and Karla Hemming and Terry Haines and Elizabeth L. Turner and Jennifer A. Thompson and James P. Hughes and Andrew B. Forbes},
   doi = {10.1177/17407745211020852},
   issn = {17407753},
   issue = {5},
   journal = {Clinical Trials},
   keywords = {Intra-cluster correlation coefficient,between-period correlation,cluster autocorrelation,cluster randomised trial,discrete-time decay,sample size,within-period correlation},
   month = {10},
   pages = {529-540},
   pmid = {34088230},
   publisher = {SAGE Publications Ltd},
   title = {Intra-cluster correlations from the CLustered OUtcome Dataset bank to inform the design of longitudinal cluster trials},
   volume = {18},
   year = {2021}
}
@article{Ouyang2023,
   abstract = {It is well-known that designing a cluster randomized trial (CRT) requires an advance estimate of the intra-cluster correlation coefficient (ICC). In the case of longitudinal CRTs, where outcomes are assessed repeatedly in each cluster over time, estimates for more complex correlation structures are required. Three common types of correlation structures for longitudinal CRTs are exchangeable, nested/block exchangeable and exponential decay correlations-The latter two allow the strength of the correlation to weaken over time. Determining sample sizes under these latter two structures requires advance specification of the within-period ICC and cluster autocorrelation coefficient as well as the intra-individual autocorrelation coefficient in the case of a cohort design. How to estimate these coefficients is a common challenge for investigators. When appropriate estimates from previously published longitudinal CRTs are not available, one possibility is to re-Analyse data from an available trial dataset or to access observational data to estimate these parameters in advance of a trial. In this tutorial, we demonstrate how to estimate correlation parameters under these correlation structures for continuous and binary outcomes. We first introduce the correlation structures and their underlying model assumptions under a mixed-effects regression framework. With practical advice for implementation, we then demonstrate how the correlation parameters can be estimated using examples and we provide programming code in R, SAS, and Stata. An Rshiny app is available that allows investigators to upload an existing dataset and obtain the estimated correlation parameters. We conclude by identifying some gaps in the literature.},
   author = {Yongdong Ouyang and Karla Hemming and Fan Li and Monica Taljaard},
   doi = {10.1093/ije/dyad062},
   issn = {14643685},
   issue = {5},
   journal = {International Journal of Epidemiology},
   keywords = {Sample size,clinical trials,cluster autocorrelation coefficient,statistical power,stepped wedge},
   month = {10},
   pages = {1634-1647},
   pmid = {37196320},
   publisher = {Oxford University Press},
   title = {Estimating intra-cluster correlation coefficients for planning longitudinal cluster randomized trials: A tutorial},
   volume = {52},
   year = {2023}
}
@article{Ouyang2022,
   abstract = {Recent years have seen a surge of interest in stepped-wedge cluster randomized trials (SW-CRTs). SW-CRTs include several design variations and methodology is rapidly developing. Accordingly, a variety of power and sample size calculation software for SW-CRTs has been developed. However, each calculator may support only a selected set of design features and may not be appropriate for all scenarios. Currently, there is no resource to assist researchers in selecting the most appropriate calculator for planning their trials. In this paper, we review and classify 18 existing calculators that can be implemented in major platforms, such as R, SAS, Stata, Microsoft Excel, PASS and nQuery. After reviewing the main sample size considerations for SW-CRTs, we summarize the features supported by the available calculators, including the types of designs, outcomes, correlation structures and treatment effects; whether incomplete designs, cluster-size variation or secular trends are accommodated; and the analytical approach used. We then discuss in more detail four main calculators and identify their strengths and limitations. We illustrate how to use these four calculators to compute power for two real SW-CRTs with a continuous and binary outcome and compare the results. We show that the choice of calculator can make a substantial difference in the calculated power and explain these differences. Finally, we make recommendations for implementing sample size or power calculations using the available calculators. An R Shiny app is available for users to select the calculator that meets their requirements (https://douyang.shinyapps.io/swcrtcalculator/).},
   author = {Yongdong Ouyang and Fan Li and John S. Preisser and Monica Taljaard},
   doi = {10.1093/ije/dyac123},
   issn = {14643685},
   issue = {6},
   journal = {International Journal of Epidemiology},
   keywords = {Stepped-wedge design,correlation structures,power,sample size,software},
   month = {12},
   pages = {2000-2013},
   pmid = {35679584},
   publisher = {Oxford University Press},
   title = {Sample size calculators for planning stepped-wedge cluster randomized trials: a review and comparison},
   volume = {51},
   year = {2022}
}
@article{Chakraborty2016,
   abstract = {Various methods have been proposed to estimate intra-cluster correlation coefficients (ICCs) for correlated binary data, and many are very sensitive to the type of design and underlying distributional assumptions. We proposed a new method to estimate ICC and its 95% confidence intervals based on resampling principles and U-statistics, where we resampled with replacement pairs of individuals from within and between clusters. We concluded from our simulation study that the resampling-based estimates approximate the population ICC more precisely than the analysis of variance and method of moments techniques for different event rates, varying number of clusters, and cluster sizes.},
   author = {Hrishikesh Chakraborty and Pranab K. Sen},
   doi = {10.1080/03610926.2013.870202},
   issn = {1532415X},
   issue = {8},
   journal = {Communications in Statistics - Theory and Methods},
   keywords = {Clustered binary data,Intra-cluster correlation,Resampling},
   month = {4},
   pages = {2368-2377},
   publisher = {Taylor and Francis Inc.},
   title = {Resampling method to estimate intra-cluster correlation for clustered binary data},
   volume = {45},
   year = {2016}
}
@article{Liu2016,
   abstract = {Summary: Agreement and correlation are widely-used concepts that assess the association between variables. Although similar and related, they represent completely different notions of association. Assessing agreement between variables assumes that the variables measure the same construct, while correlation of variables can be assessed for variables that measure completely different constructs. This conceptual difference requires the use of different statistical methods, and when assessing agreement or correlation, the statistical method may vary depending on the distribution of the data and the interest of the investigator. For example, the Pearson correlation, a popular measure of correlation between continuous variables, is only informative when applied to variables that have linear relationships; it may be non-informative or even misleading when applied to variables that are not linearly related. Likewise, the intraclass correlation, a popular measure of agreement between continuous variables, may not provide sufficient information for investigators if the nature of poor agreement is of interest. This report reviews the concepts of agreement and correlation and discusses differences in the application of several commonly used measures.},
   author = {Jinyuan Liu and Wan Tang and Guanqin Chen and Yin Lu and Changyong Feng and Xin M. Tu},
   doi = {10.11919/j.issn.1002-0829.216045},
   issn = {10020829},
   issue = {2},
   journal = {Shanghai Archives of Psychiatry},
   keywords = {Concordance correlation,Intraclass correlation,Kendall's tau,Non-linear association,Pearson's correlation,Spearman's rho},
   month = {4},
   pages = {115-120},
   pmid = {27605869},
   publisher = {Editorial Department of theShanghai Archives of Psychiatry},
   title = {Correlation and agreement: overview and clarification of competing concepts and measures},
   volume = {28},
   year = {2016}
}
@techReport{Atenafu2012,
   abstract = {Background: Intraclass correlation coefficients (ICCs) are used in a wide range of applications. However, most commonly used estimators for the ICC are known to be subject to bias. Methods: Using second order Taylor series expansion, we propose a new bias-corrected estimator for one type of intraclass correlation coefficient, for the ICC that arises in the context of the balanced one-way random effects model. A simulation study is performed to assess the performance of the proposed estimator. Data have been generated under normal as well as non-normal scenarios. Results: Our simulation results show that the new estimator has reduced bias compared to the least square estimator which is often referred to as the conventional or analytical estimator. The results also show marked bias reduction both in normal and non-normal data scenarios. In particular, our estimator outperforms the analytical estimator in a non-normal setting producing estimates that are very close to the true ICC values. Conclusions: The proposed bias-corrected estimator for the ICC from a one-way random effects analysis of variance model appears to perform well in the scenarios we considered in this paper and can be used as a motivation to construct bias-corrected estimators for other types of ICCs that arise in more complex scenarios. It would also be interesting to investigate the bias-variance trade-off. Background},
   author = {Eshetu G Atenafu and Jemila S Hamid and Teresa To and Andrew R Willan and Brian M Feldman and Joseph Beyene},
   journal = {BMC Medical Research Methodology},
   pages = {126},
   title = {Bias-corrected estimator for intraclass correlation coefficient in the balanced one-way random effects model},
   volume = {12},
   url = {http://www.biomedcentral.com/1471-2288/12/126},
   year = {2012}
}
@techReport{Liang1986,
   author = {Kung-Yee Liang and Scott L Zeger},
   issue = {1},
   pages = {13-22},
   title = {Longitudinal Data Analysis Using Generalized Linear Models},
   volume = {73},
   url = {https://www.jstor.org/stable/2336267},
   year = {1986}
}
@techReport{Donner1986,
   abstract = {JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide range of content in a trusted digital archive. We use information technology and tools to increase productivity and facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org. Summary Recent theory and methodology for inferences concerning the intraclass correlation coefficient are reviewed, under the assumption of an underlying random effects model. Topics discussed include point and interval estimation, significance-testing for nonzero values of the intraclass correlation, and inference procedures in multiple samples.},
   author = {Allan Donner},
   issue = {1},
   journal = {International Statistical Review},
   keywords = {Intraclass correlation,Random model,Statistical inference,Variance components},
   pages = {67-82},
   title = {A Review of Inference Procedures for the Intraclass Correlation Coefficient in the One-Way Random Effects Model},
   volume = {54},
   year = {1986}
}
@article{Chakraborty2018,
   abstract = {Background and Objective The Intracluster Correlation Coefficient (ICC) is a major parameter of interest in cluster randomized trials that measures the degree to which responses within the same cluster are correlated. There are several types of ICC estimators and its confidence intervals (CI) suggested in the literature for binary data. Studies have compared relative weaknesses and advantages of ICC estimators as well as its CI for binary data and suggested situations where one is advantageous in practical research. The commonly used statistical computing systems currently facilitate estimation of only a very few variants of ICC and its CI. To address the limitations of current statistical packages, we developed an R package, ICCbin, to facilitate estimating ICC and its CI for binary responses using different methods. Methods The ICCbin package is designed to provide estimates of ICC in 16 different ways including analysis of variance methods, moments based estimation, direct probabilistic methods, correlation based estimation, and resampling method. CI of ICC is estimated using 5 different methods. It also generates cluster binary data using exchangeable correlation structure. Results ICCbin package provides two functions for users. The function rcbin generates cluster binary data and the function iccbin estimates ICC and it's CI. The users can choose appropriate ICC and its CI estimate from the wide selection of estimates from the outputs. Conclusions The R package ICCbin presents very flexible and easy to use ways to generate cluster binary data and to estimate ICC and it's CI for binary response using different methods. The package ICCbin is freely available for use with R from the CRAN repository (https://cran.r-project.org/package=ICCbin). We believe that this package can be a very useful tool for researchers to design cluster randomized trials with binary outcome.},
   author = {Hrishikesh Chakraborty and Akhtar Hossain},
   doi = {10.1016/j.cmpb.2017.10.023},
   issn = {18727565},
   journal = {Computer Methods and Programs in Biomedicine},
   keywords = {Confidence interval of ICC,ICCbin,Intracluster correlation coefficient,R package,Randomized clinical trials},
   month = {3},
   pages = {85-92},
   pmid = {29512507},
   publisher = {Elsevier Ireland Ltd},
   title = {R package to estimate intracluster correlation coefficient with confidence interval for binary data},
   volume = {155},
   year = {2018}
}
@article{Lewis2021,
   abstract = {Sample size calculations for cluster-randomised trials require inclusion of an inflation factor taking into account the intra-cluster correlation coefficient. Often, estimates of the intra-cluster correlation coefficient are taken from pilot trials, which are known to have uncertainty about their estimation. Given that the value of the intra-cluster correlation coefficient has a considerable influence on the calculated sample size for a main trial, the uncertainty in the estimate can have a large impact on the ultimate sample size and consequently, the power of a main trial. As such, it is important to account for the uncertainty in the estimate of the intra-cluster correlation coefficient. While a commonly adopted approach is to utilise the upper confidence limit in the sample size calculation, this is a largely inefficient method which can result in overpowered main trials. In this paper, we present a method of estimating the sample size for a main cluster-randomised trial with a continuous outcome, using numerical methods to account for the uncertainty in the intra-cluster correlation coefficient estimate. Despite limitations with this initial study, the findings and recommendations in this paper can help to improve sample size estimations for cluster randomised controlled trials by accounting for uncertainty in the estimate of the intra-cluster correlation coefficient. We recommend this approach be applied to all trials where there is uncertainty in the intra-cluster correlation coefficient estimate, in conjunction with additional sources of information to guide the estimation of the intra-cluster correlation coefficient.},
   author = {Jen Lewis and Steven A. Julious},
   doi = {10.1177/09622802211037073},
   issn = {14770334},
   issue = {11},
   journal = {Statistical Methods in Medical Research},
   keywords = {Cluster-randomised,cluster trial,imprecision,intra-cluster correlation,intra-cluster correlation coefficient,sample size},
   month = {11},
   pages = {2459-2470},
   pmid = {34477455},
   publisher = {SAGE Publications Ltd},
   title = {Sample sizes for cluster-randomised trials with continuous outcomes: Accounting for uncertainty in a single intra-cluster correlation estimate},
   volume = {30},
   year = {2021}
}
@article{Hemming2020,
   abstract = {It has long been recognized that sample size calculations for cluster randomized trials require consideration of the correlation between multiple observations within the same cluster. When measurements are taken at anything other than a single point in time, these correlations depend not only on the cluster but also on the time separation between measurements and additionally, on whether different participants (cross-sectional designs) or the same participants (cohort designs) are repeatedly measured. This is particularly relevant in trials with multiple periods of measurement, such as the cluster cross-over and stepped-wedge designs, but also to some degree in parallel designs. Several papers describing sample size methodology for these designs have been published, but this methodology might not be accessible to all researchers. In this article we provide a tutorial on sample size calculation for cluster randomized designs with particular emphasis on designs with multiple periods of measurement and provide a web-based tool, the Shiny CRT Calculator, to allow researchers to easily conduct these sample size calculations. We consider both cross-sectional and cohort designs and allow for a variety of assumed within-cluster correlation structures. We consider cluster heterogeneity in treatment effects (for designs where treatment is crossed with cluster), as well as individually randomized group-treatment trials with differential clustering between arms, for example designs where clustering arises from interventions being delivered in groups. The calculator will compute power or precision, as a function of cluster size or number of clusters, for a wide variety of designs and correlation structures. We illustrate the methodology and the flexibility of the Shiny CRT Calculator using a range of examples.},
   author = {Karla Hemming and Jessica Kasza and Richard Hooper and Andrew Forbes and Monica Taljaard},
   doi = {10.1093/IJE/DYZ237},
   issn = {14643685},
   issue = {3},
   journal = {International Journal of Epidemiology},
   pages = {979-995},
   pmid = {32087011},
   publisher = {Oxford University Press},
   title = {A tutorial on sample size calculation for multiple-period cluster randomized parallel, cross-over and stepped-wedge trials using the shiny CRT calculator},
   volume = {49},
   year = {2020}
}
@article{Westgate2019,
   abstract = {Background/aims: Cluster randomized trials are popular in health-related research due to the need or desire to randomize clusters of subjects to different trial arms as opposed to randomizing each subject individually. As outcomes from subjects within the same cluster tend to be more alike than outcomes from subjects within other clusters, an exchangeable correlation arises that is measured via the intra-cluster correlation coefficient. Intra-cluster correlation coefficient estimation is especially important due to the increasing awareness of the need to publish such values from studies in order to help guide the design of future cluster randomized trials. Therefore, numerous methods have been proposed to accurately estimate the intra-cluster correlation coefficient, with much attention given to binary outcomes. As marginal models are often of interest, we focus on intra-cluster correlation coefficient estimation in the context of fitting such a model with binary outcomes using generalized estimating equations. Traditionally, intra-cluster correlation coefficient estimation with generalized estimating equations has been based on the method of moments, although such estimators can be negatively biased. Furthermore, alternative estimators that work well, such as the analysis of variance estimator, are not as readily applicable in the context of practical data analyses with generalized estimating equations. Therefore, in this article we assess, in terms of bias, the readily available residual pseudo-likelihood approach to intra-cluster correlation coefficient estimation with the GLIMMIX procedure of SAS (SAS Institute, Cary, NC). Furthermore, we study a possible corresponding approach to confidence interval construction for the intra-cluster correlation coefficient. Methods: We utilize a simulation study and application example to assess bias in intra-cluster correlation coefficient estimates obtained from GLIMMIX using residual pseudo-likelihood. This estimator is contrasted with method of moments and analysis of variance estimators which are standards of comparison. The approach to confidence interval construction is assessed by examining coverage probabilities. Results: Overall, the residual pseudo-likelihood estimator performs very well. It has considerably less bias than moment estimators, which are its competitor for general generalized estimating equation–based analyses, and therefore, it is a major improvement in practice. Furthermore, it works almost as well as analysis of variance estimators when they are applicable. Confidence intervals have near-nominal coverage when the intra-cluster correlation coefficient estimate has negligible bias. Conclusion: Our results show that the residual pseudo-likelihood estimator is a good option for intra-cluster correlation coefficient estimation when conducting a generalized estimating equation–based analysis of binary outcome data arising from cluster randomized trials. The estimator is practical in that it is simply a result from fitting a marginal model with GLIMMIX, and a confidence interval can be easily obtained. An additional advantage is that, unlike most other options for performing generalized estimating equation–based analyses, GLIMMIX provides analysts the option to utilize small-sample adjustments that ensure valid inference.},
   author = {Philip M. Westgate},
   doi = {10.1177/1740774518803635},
   issn = {17407753},
   issue = {1},
   journal = {Clinical Trials},
   keywords = {Empirical covariance matrix,generalized estimating equations,group randomized trial,method of moments,residual pseudo-likelihood,small-sample corrections},
   month = {2},
   pages = {41-51},
   pmid = {30295512},
   publisher = {SAGE Publications Ltd},
   title = {A readily available improvement over method of moments for intra-cluster correlation estimation in the context of cluster randomized trials and fitting a GEE–type marginal model for binary outcomes},
   volume = {16},
   year = {2019}
}
@article{Wu2012,
   abstract = {The intraclass correlation coefficient (ICC) is a fundamental parameter of interest in cluster randomized trials as it can greatly affect statistical power. We compare common methods of estimating the ICC in cluster randomized trials with binary outcomes, with a specific focus on their application to community-based cancer prevention trials with primary outcome of self-reported cancer screening. Using three real data sets from cancer screening intervention trials with different numbers and types of clusters and cluster sizes, we obtained point estimates and 95% confidence intervals for the ICC using five methods: the analysis of variance estimator, the Fleiss-Cuzick estimator, the Pearson estimator, an estimator based on generalized estimating equations and an estimator from a random intercept logistic regression model. We compared estimates of the ICC for the overall sample and by study condition. Our results show that ICC estimates from different methods can be quite different, although confidence intervals generally overlap. The ICC varied substantially by study condition in two studies, suggesting that the common practice of assuming a common ICC across all clusters in the trial is questionable. A simulation study confirmed pitfalls of erroneously assuming a common ICC. Investigators should consider using sample size and analysis methods that allow the ICC to vary by study condition. © 2012.},
   author = {Sheng Wu and Catherine M. Crespi and Weng Kee Wong},
   doi = {10.1016/j.cct.2012.05.004},
   issn = {15517144},
   issue = {5},
   journal = {Contemporary Clinical Trials},
   keywords = {Cancer screening,Cluster randomized trials,Correlated binary data,Intervention trials,Intraclass correlation coefficient},
   month = {9},
   pages = {869-880},
   pmid = {22627076},
   title = {Comparison of methods for estimating the intraclass correlation coefficient for binary responses in cancer prevention cluster randomized trials},
   volume = {33},
   year = {2012}
}
@article{Nakagawa2017,
   abstract = {The coefficient of determination R2 quantifies the proportion of variance explained by a statistical model and is an important summary statistic of biological interest. However, estimating R2 for generalized linear mixed models (GLMMs) remains challenging. We have previously introduced a version of R2 that we called R2 GLMM for Poisson and binomial GLMMs, but not for other distributional families. Similarly, we earlier discussed how to estimate intra-class correlation coefficients (ICCs) using Poisson and binomial GLMMs. In this paper, we generalize our methods to all other non-Gaussian distributions, in particular to negative binomial and gamma distributions that are commonly used for modelling biological data. While expanding our approach, we highlight two useful concepts for biologists, Jensen's inequality and the delta method, both of which help us in understanding the properties of GLMMs. Jensen's inequality has important implications for biologically meaningful interpretation of GLMMs, whereas the delta method allows a general derivation of variance associated with non-Gaussian distributions. We also discuss some special considerations for binomial GLMMs with binary or proportion data. We illustrate the implementation of our extension by worked examples from the field of ecology and evolution in the R environment. However, our method can be used across disciplines and regardless of statistical environments.},
   author = {Shinichi Nakagawa and Paul C.D. Johnson and Holger Schielzeth},
   doi = {10.1098/rsif.2017.0213},
   issn = {17425662},
   issue = {134},
   journal = {Journal of the Royal Society Interface},
   keywords = {Goodness of fit,Heritability,Model fit,Reliability analysis,Repeatability,Variance decomposition},
   month = {9},
   pmid = {28904005},
   publisher = {Royal Society Publishing},
   title = {The coefficient of determination R2 and intra-class correlation coefficient from generalized linear mixed-effects models revisited and expanded},
   volume = {14},
   year = {2017}
}
@misc{Chang2012,
   author = {Winston Chang and Joe Cheng and JJ Allaire and Carson Sievert and Barret Schloerke and Yihui Xie and Jeff Allen and Jonathan McPherson and Alan Dipert and Barbara Borges},
   doi = {10.32614/CRAN.package.shiny},
   journal = {CRAN: Contributed Packages},
   month = {12},
   title = {shiny: Web Application Framework for R},
   year = {2012}
}
@article{Sarkodie2024,
   abstract = {This study presents a hybrid (Bayesian-frequentist) approach to sample size re-estimation (SSRE) for cluster randomised trials with continuous outcome data, allowing for uncertainty in the intra-cluster correlation (ICC). In the hybrid framework, pre-trial knowledge about the ICC is captured by placing a Truncated Normal prior on it, which is then updated at an interim analysis using the study data, and used in expected power control. On average, both the hybrid and frequentist approaches mitigate against the implications of misspecifying the ICC at the trial's design stage. In addition, both frameworks lead to SSRE designs with approximate control of the type I error-rate at the desired level. It is clearly demonstrated how the hybrid approach is able to reduce the high variability in the re-estimated sample size observed within the frequentist framework, based on the informativeness of the prior. However, misspecification of a highly informative prior can cause significant power loss. In conclusion, a hybrid approach could offer advantages to cluster randomised trials using SSRE. Specifically, when there is available data or expert opinion to help guide the choice of prior for the ICC, the hybrid approach can reduce the variance of the re-estimated required sample size compared to a frequentist approach. As SSRE is unlikely to be employed when there is substantial amounts of such data available (ie, when a constructed prior is highly informative), the greatest utility of a hybrid approach to SSRE likely lies when there is low-quality evidence available to guide the choice of prior.},
   author = {Samuel K. Sarkodie and James M.S. Wason and Michael J. Grayling},
   doi = {10.1002/sim.10205},
   issn = {10970258},
   issue = {24},
   journal = {Statistics in Medicine},
   keywords = {Bayesian-frequentist,adaptive design,expected power,hybrid design,interim analysis,internal pilot,intra-class correlation},
   month = {10},
   pages = {4736-4751},
   pmid = {39193805},
   publisher = {John Wiley and Sons Ltd},
   title = {A hybrid approach to sample size re-estimation in cluster randomized trials with continuous outcomes},
   volume = {43},
   year = {2024}
}
@article{Sarkodie2023,
   abstract = {Background/Aims: To evaluate how uncertainty in the intra-cluster correlation impacts whether a parallel-group or stepped-wedge cluster-randomized trial design is more efficient in terms of the required sample size, in the case of cross-sectional stepped-wedge cluster-randomized trials and continuous outcome data. Methods: We motivate our work by reviewing how the intra-cluster correlation and standard deviation were justified in 54 health technology assessment reports on cluster-randomized trials. To enable uncertainty at the design stage to be incorporated into the design specification, we then describe how sample size calculation can be performed for cluster- randomized trials in the ‘hybrid’ framework, which places priors on design parameters and controls the expected power in place of the conventional frequentist power. Comparison of the parallel-group and stepped-wedge cluster-randomized trial designs is conducted by placing Beta and truncated Normal priors on the intra-cluster correlation, and a Gamma prior on the standard deviation. Results: Many Health Technology Assessment reports did not adhere to the Consolidated Standards of Reporting Trials guideline of indicating the uncertainty around the assumed intra-cluster correlation, while others did not justify the assumed intra-cluster correlation or standard deviation. Even for a prior intra-cluster correlation distribution with a small mode, moderate prior densities on high intra-cluster correlation values can lead to a stepped-wedge cluster-randomized trial being more efficient because of the degree to which a stepped-wedge cluster-randomized trial is more efficient for high intra-cluster correlations. With careful specification of the priors, the designs in the hybrid framework can become more robust to, for example, an unexpectedly large value of the outcome variance. Conclusion: When there is difficulty obtaining a reliable value for the intra-cluster correlation to assume at the design stage, the proposed methodology offers an appealing approach to sample size calculation. Often, uncertainty in the intra-cluster correlation will mean a stepped-wedge cluster-randomized trial is more efficient than a parallel-group cluster-randomized trial design.},
   author = {Samuel K. Sarkodie and James M.S. Wason and Michael J. Grayling},
   doi = {10.1177/17407745221123507},
   issn = {17407753},
   issue = {1},
   journal = {Clinical Trials},
   keywords = {Assurance,Bayesian-frequentist,expected power,hybrid design,intra-class correlation},
   month = {2},
   pages = {59-70},
   pmid = {36086822},
   publisher = {SAGE Publications Ltd},
   title = {A hybrid approach to comparing parallel-group and stepped-wedge cluster-randomized trials with a continuous primary outcome when there is uncertainty in the intra-cluster correlation},
   volume = {20},
   year = {2023}
}
@misc{Offorha2022,
   abstract = {Background: In cluster randomised controlled trials (cRCTs), groups of individuals (rather than individuals) are randomised to minimise the risk of contamination and/or efficiently use limited resources or solve logistic and administrative problems. A major concern in the primary analysis of cRCT is the use of appropriate statistical methods to account for correlation among outcomes from a particular group/cluster. This review aimed to investigate the statistical methods used in practice for analysing the primary outcomes in publicly funded cluster randomised controlled trials, adherence to the CONSORT (Consolidated Standards of Reporting Trials) reporting guidelines for cRCTs and the recruitment abilities of the cluster trials design. Methods: We manually searched the United Kingdom’s National Institute for Health Research (NIHR) online Journals Library, from 1 January 1997 to 15 July 2021 chronologically for reports of cRCTs. Information on the statistical methods used in the primary analyses was extracted. One reviewer conducted the search and extraction while the two other independent reviewers supervised and validated 25% of the total trials reviewed. Results: A total of 1942 reports, published online in the NIHR Journals Library were screened for eligibility, 118 reports of cRCTs met the initial inclusion criteria, of these 79 reports containing the results of 86 trials with 100 primary outcomes analysed were finally included. Two primary outcomes were analysed at the cluster-level using a generalized linear model. At the individual-level, the generalized linear mixed model was the most used statistical method (80%, 80/100), followed by regression with robust standard errors (7%) then generalized estimating equations (6%). Ninety-five percent (95/100) of the primary outcomes in the trials were analysed with appropriate statistical methods that accounted for clustering while 5% were not. The mean observed intracluster correlation coefficient (ICC) was 0.06 (SD, 0.12; range, − 0.02 to 0.63), and the median value was 0.02 (IQR, 0.001–0.060), although 42% of the observed ICCs for the analysed primary outcomes were not reported. Conclusions: In practice, most of the publicly funded cluster trials adjusted for clustering using appropriate statistical method(s), with most of the primary analyses done at the individual level using generalized linear mixed models. However, the inadequate analysis and poor reporting of cluster trials published in the UK is still happening in recent times, despite the availability of the CONSORT reporting guidelines for cluster trials published over a decade ago.},
   author = {Bright C. Offorha and Stephen J. Walters and Richard M. Jacques},
   doi = {10.1186/s13063-022-06025-1},
   issn = {17456215},
   issue = {1},
   journal = {Trials},
   keywords = {CONSORT,Cluster randomised controlled trials,Clustering,Intracluster correlation coefficient,Recruitment,Statistical methods},
   month = {12},
   pmid = {35120567},
   publisher = {BioMed Central Ltd},
   title = {Statistical analysis of publicly funded cluster randomised controlled trials: a review of the National Institute for Health Research Journals Library},
   volume = {23},
   year = {2022}
}
@article{Ivers2011,
   abstract = {Objective: To assess the impact of the 2004 extension of the CONSORT guidelines on the reporting and methodological quality of cluster randomised trials. Design: Methodological review of 300 randomly sampled cluster randomised trials. Two reviewers independently abstracted 14 criteria related to quality of reporting and four methodological criteria specific to cluster randomised trials. We compared manuscripts published before CONSORT (2000-4) with those published after CONSORT (2005-8). We also investigated differences by journal impact factor, type of journal, and trial setting. Data sources: A validated Medline search strategy. Eligibility criteria for selecting studies: Cluster randomised trials published in English language journals, 2000-8. Results: There were significant improvements in five of 14 reporting criteria: identification as cluster randomised; justification for cluster randomisation; reporting whether outcome assessments were blind; reporting the number of clusters randomised; and reporting the number of clusters lost to follow-up. No significant improvements were found in adherence to methodological criteria. Trials conducted in clinical rather than non-clinical settings and studies published in medical journals with higher impact factor or general medical journals were more likely to adhere to recommended reporting and methodological criteria overall, but there was no evidence that improvements after publication of the CONSORT extension for cluster trials were more likely in trials conducted in clinical settings nor in trials published in either general medical journals or in higher impact factor journals. Conclusion: The quality of reporting of cluster randomised trials improved in only a few aspects since the publication of the extension of CONSORT for cluster randomised trials, and no improvements at all were observed in essential methodological features. Overall, the adherence to reporting and methodological guidelines for cluster randomised trials remains suboptimal, and further efforts are needed to improve both reporting and methodology.},
   author = {N. M. Ivers and M. Taljaard and S. Dixon and C. Bennett and A. McRae and J. Taleban and Z. Skea and J. C. Brehaut and R. F. Boruch and M. P. Eccles and J. M. Grimshaw and C. Weijer and M. Zwarenstein and A. Donner},
   doi = {10.1136/bmj.d5886},
   issn = {09598146},
   issue = {7827},
   journal = {BMJ (Online)},
   month = {10},
   pmid = {21948873},
   title = {Impact of CONSORT extension for cluster randomised trials on quality of reporting and study methodology: Review of random sample of 300 trials, 2000-8},
   volume = {343},
   year = {2011}
}
@article{Campbell2012,
   author = {Marion K. Campbell and Gilda Piaggio and Diana R. Elbourne and Douglas G. Altman},
   doi = {10.1136/bmj.e5661},
   issn = {17561833},
   issue = {7881},
   journal = {BMJ (Online)},
   month = {11},
   pmid = {22951546},
   title = {Consort 2010 statement: Extension to cluster randomised trials},
   volume = {345},
   year = {2012}
}
@article{Hemming2016,
   abstract = {Objectives To clarify and illustrate sample size calculations for the cross-sectional stepped wedge cluster randomized trial (SW-CRT) and to present a simple approach for comparing the efficiencies of competing designs within a unified framework. Study Design and Setting We summarize design effects for the SW-CRT, the parallel cluster randomized trial (CRT), and the parallel cluster randomized trial with before and after observations (CRT-BA), assuming cross-sectional samples are selected over time. We present new formulas that enable trialists to determine the required cluster size for a given number of clusters. We illustrate by example how to implement the presented design effects and give practical guidance on the design of stepped wedge studies. Results For a fixed total cluster size, the choice of study design that provides the greatest power depends on the intracluster correlation coefficient (ICC) and the cluster size. When the ICC is small, the CRT tends to be more efficient; when the ICC is large, the SW-CRT tends to be more efficient and can serve as an alternative design when the CRT is an infeasible design. Conclusion Our unified approach allows trialists to easily compare the efficiencies of three competing designs to inform the decision about the most efficient design in a given scenario.},
   author = {Karla Hemming and Monica Taljaard},
   doi = {10.1016/j.jclinepi.2015.08.015},
   issn = {18785921},
   journal = {Journal of Clinical Epidemiology},
   keywords = {Cluster randomized trial,Efficiency,Power,Sample size,Stepped wedge,Study design},
   month = {1},
   pages = {137-146},
   pmid = {26344808},
   publisher = {Elsevier USA},
   title = {Sample size calculations for stepped wedge and cluster randomised trials: A unified approach},
   volume = {69},
   year = {2016}
}
@article{Teare2014,
   abstract = {Background: External pilot or feasibility studies can be used to estimate key unknown parameters to inform the design of the definitive randomised controlled trial (RCT). However, there is little consensus on how large pilot studies need to be, and some suggest inflating estimates to adjust for the lack of precision when planning the definitive RCT.Methods: We use a simulation approach to illustrate the sampling distribution of the standard deviation for continuous outcomes and the event rate for binary outcomes. We present the impact of increasing the pilot sample size on the precision and bias of these estimates, and predicted power under three realistic scenarios. We also illustrate the consequences of using a confidence interval argument to inflate estimates so the required power is achieved with a pre-specified level of confidence. We limit our attention to external pilot and feasibility studies prior to a two-parallel-balanced-group superiority RCT.Results: For normally distributed outcomes, the relative gain in precision of the pooled standard deviation (SD<inf>p</inf>) is less than 10% (for each five subjects added per group) once the total sample size is 70. For true proportions between 0.1 and 0.5, we find the gain in precision for each five subjects added to the pilot sample is less than 5% once the sample size is 60. Adjusting the required sample sizes for the imprecision in the pilot study estimates can result in excessively large definitive RCTs and also requires a pilot sample size of 60 to 90 for the true effect sizes considered here.Conclusions: We recommend that an external pilot study has at least 70 measured subjects (35 per group) when estimating the SD<inf>p</inf> for a continuous outcome. If the event rate in an intervention group needs to be estimated by the pilot then a total of 60 to 100 subjects is required. Hence if the primary outcome is binary a total of at least 120 subjects (60 in each group) may be required in the pilot trial. It is very much more efficient to use a larger pilot study, than to guard against the lack of precision by using inflated estimates. © 2014 Teare et al.; licensee BioMed Central Ltd.},
   author = {M. D. Teare and Munyaradzi Dimairo and Neil Shephard and Alex Hayman and Amy Whitehead and Stephen J. Walters},
   doi = {10.1186/1745-6215-15-264},
   issn = {17456215},
   issue = {1},
   journal = {Trials},
   keywords = {binary outcomes,continuous outcomes, RCTs,feasibility studies,pilot studies,sample size},
   month = {7},
   pmid = {24993581},
   publisher = {BioMed Central Ltd.},
   title = {Sample size requirements to estimate key design parameters from external pilot randomised controlled trials: A simulation study},
   volume = {15},
   year = {2014}
}
@article{Liljequist2019,
   abstract = {A re-analysis of intraclass correlation (ICC) theory is presented together with Monte Carlo simulations of ICC probability distributions. A partly revised and simplified theory of the single-score ICC is obtained, together with an alternative and simple recipe for its use in reliability studies. Our main, practical conclusion is that in the analysis of a reliability study it is neither necessary nor convenient to start from an initial choice of a specified statistical model. Rather, one may impartially use all three single-score ICC formulas. A near equality of the three ICC values indicates the absence of bias (systematic error), in which case the classical (one-way random) ICC may be used. A consistency ICC larger than absolute agreement ICC indicates the presence of non-negligible bias; if so, classical ICC is invalid and misleading. An F-test may be used to confirm whether biases are present. From the resulting model (without or with bias) variances and confidence intervals may then be calculated. In presence of bias, both absolute agreement ICC and consistency ICC should be reported, since they give different and complementary information about the reliability of the method. A clinical example with data from the literature is given.},
   author = {David Liljequist and Britt Elfving and Kirsti Skavberg Roaldsen},
   doi = {10.1371/journal.pone.0219854},
   issn = {19326203},
   issue = {7},
   journal = {PLoS ONE},
   month = {7},
   pmid = {31329615},
   publisher = {Public Library of Science},
   title = {Intraclass correlation – A discussion and demonstration of basic features},
   volume = {14},
   year = {2019}
}
@article{Killip2004,
   abstract = {BACKGROUND: Primary care research often involves clustered samples in which subjects are randomized at a group level but analyzed at an individual level. Analyses that do not take this clustering into account may report significance where none exists. This article explores the causes, consequences, and implications of cluster data. METHODS: Using a case study with accompanying equations, we show that clustered samples are not as statistically efficient as simple random samples. RESULTS: Similarity among subjects within preexisting groups or clusters reduces the variability of responses in a clustered sample, which erodes the power to detect true differences between study arms. This similarity is expressed by the intracluster correlation coefficient, or ρ (rho), which compares the within-group variance with the between-group variance. Rho is used in equations along with the cluster size and the number of clusters to calculate the effective sample size (ESS) in a clustered design. The ESS should be used to calculate power in the design phase of a clustered study. Appropriate accounting for similarities among subjects in a cluster almost always results in a net loss of power, requiring increased total subject recruitment. Increasing the number of clusters enhances power more efficiently than does increasing the number of subjects within a cluster. CONCLUSIONS: Primary care research frequently uses clustered designs, whether consciously or unconsciously. Researchers must recognize and understand the implications of clusters to avoid costly sample size errors.},
   author = {Shersten Killip and Ziyad Mahfoud and Kevin Pearce},
   doi = {10.1370/afm.141},
   issn = {15441709},
   issue = {3},
   journal = {Annals of Family Medicine},
   keywords = {Cluster analysis,Data interpretation, research design,Methods/quantitative,Practice-based research,Primary care,Statistics,Theory},
   month = {5},
   pages = {204-208},
   pmid = {15209195},
   title = {What is an intracluster correlation coefficient? Crucial concepts for primary care researchers},
   volume = {2},
   year = {2004}
}
@article{Eldridge2009,
   abstract = {The intra-cluster correlation coefficient (ICC) of the primary outcome plays a key role in the design and analysis of cluster randomized trials (CRTs), but the precise definition of this parameter is somewhat elusive, especially in the context of non-normally distributed outcomes. In this paper, we provide a unified treatment of ICC as used in CRTs. We present a general definition of the ICC that may be expressed in different ways depending on the modelling approach used to describe the data, illustrating how this general definition is applied to continuous and dichotomous outcomes. Greater complexity arises for dichotomous outcomes; in particular, the usual definition of the ICC cannot be related directly to the parameters of the logistic-normal model that is commonly used for dichotomous outcomes. We show how the definition of the ICC is different when covariates are introduced. Finally, we use our framework and definition of the ICC to draw out implications for those interpreting and choosing values of the ICC when planning CRTs. © 2009 International Statistical Institute.},
   author = {Sandra M. Eldridge and Obioha C. Ukoumunne and John B. Carlin},
   doi = {10.1111/j.1751-5823.2009.00092.x},
   issn = {03067734},
   issue = {3},
   journal = {International Statistical Review},
   keywords = {Cluster randomized trials,Intra-cluster correlation coefficient},
   month = {12},
   pages = {378-394},
   title = {The intra-cluster correlation coefficient in cluster randomized trials: A review of definitions},
   volume = {77},
   year = {2009}
}
@article{Murphy2006,
   abstract = {Background: Cluster randomized trials occur when groups or clusters of individuals, rather than the individuals themselves, are randomized to intervention and control groups and outcomes are measured on individuals within those clusters. Within primary care, between 1997 and 2000, there has been a virtual doubling in the number of published cluster randomized trials. A recent systematic review, specifically within primary care, found study quality to be both generally lower than that reported elsewhere and not to have shown any recent quality improvement. Objective: To discuss the design, conduct and analysis of cluster randomized trials within primary care in terms of the appropriate expertise required, potential bias, ethical considerations and expense. Discussion: Compared with trials that involve the randomization of individual participants, cluster randomized trials are more complex to design and analyse and, for a given sample size, have decreased power and a broadening of confidence intervals. Cluster randomized trials are specifically prone to potential bias at two levels - the cluster and individual. Regarding the former, it is recommended that cluster allocation be undertaken by a party independent to the research team and careful consideration be given to ensure minimal cluster attrition. Bias at the individual level can be overcome by identifying trial participants before randomization and at this time obtaining consent for intervention, data collection or both. A unique ethical aspect to cluster randomized trials is that cluster leaders may consent to the trial on behalf of potential cluster members. Additional costs of cluster randomized trials include the increased number of patients required, the complexity in their design and conduct and, usually, the need to recruit clusters de novo. Conclusion: Cluster randomized trialsare a powerful and increasingly popular research tool. They are uniquely placed for the conduct of research within primary-care clusters where intracluster contamination can occur. Associated methodological issues are straightforward and surmountable and just need careful consideration and management.},
   author = {Andrew W. Murphy and Adrian Esterman and Louis S. Pilotto},
   doi = {10.1080/13814780600780627},
   issn = {13814788},
   issue = {2},
   journal = {European Journal of General Practice},
   keywords = {Cluster randomized controlled trials,Primary care,Research methodology},
   month = {9},
   pages = {70-73},
   pmid = {16945880},
   title = {Cluster randomized controlled trials in primary care: An introduction},
   volume = {12},
   year = {2006}
}
